{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set \")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set \")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set \")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(system_msg, user_prompt, client, Model):\n",
    "    messages = [{\"role\": \"system\", \"content\":system_msg},{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(model=Model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(conversation, openai_model):\n",
    "    openai_system = \"\"\"\n",
    "    You are Blake, a very polite, courteous chatbot. You try to agree with everything the other person says, or find common ground. \n",
    "    If the other person is argumentative, you try to calm them down and keep chatting.\n",
    "    You are in a conversation with Alex and Charlie.\n",
    "    \"\"\"\n",
    "\n",
    "    openai_user_prompt = f\"\"\"\n",
    "    You are Blake, in conversation with Alex and Charlie.\n",
    "    The conversation so far is as follows:\n",
    "    {conversation}\n",
    "    Now with this, respond with what you would like to say next, as Blake.\n",
    "    \"\"\"\n",
    "    response = call_llm(openai_system, openai_user_prompt, openai, openai_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb06d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(conversation, gemini_model):\n",
    "    gemini_system = \"\"\"\n",
    "    You are Alex, a chatbot who is very argumentative; you disagree with anything in the conversation and you challenge everything, in a snarky way.\n",
    "    You are in a conversation with Blake and Charlie.\n",
    "    \"\"\"\n",
    "\n",
    "    gemini_user_prompt = f\"\"\"\n",
    "    You are Alex, in conversation with Blake and Charlie.\n",
    "    The conversation so far is as follows:\n",
    "    {conversation}\n",
    "    Now with this, respond with what you would like to say next, as Alex.\n",
    "    \"\"\"\n",
    "    response = call_llm(gemini_system, gemini_user_prompt, gemini, gemini_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_anthropic(conversation, anthropic_model):\n",
    "    anthropic_system = \"\"\"\n",
    "    You are Charlie, a chatbot who is very friendly and supportive. You try to find common ground with everyone and keep the conversation positive.\n",
    "    You are in a conversation with Alex and Blake.\n",
    "    \"\"\"\n",
    "\n",
    "    anthropic_user_prompt = f\"\"\"\n",
    "    You are Charlie, in conversation with Alex and Blake.\n",
    "    The conversation so far is as follows:\n",
    "    {conversation}\n",
    "    Now with this, respond with what you would like to say next, as Charlie.\n",
    "    \"\"\"\n",
    "    response = call_llm(anthropic_system, anthropic_user_prompt, anthropic, anthropic_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a677810",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"\"\"Blake: hii\n",
    "Alex: hello\n",
    "Charlie: hey there!\n",
    "\"\"\"\n",
    "\n",
    "for i in range(5):\n",
    "    openai_blake = call_openai(conversation, openai_model=\"gpt-4.1-mini\")\n",
    "    display(Markdown(f\"### GPT:(blake) \\n{openai_blake}\\n\"))\n",
    "    conversation += f\"\\nBlake: {openai_blake}\\n\"\n",
    "\n",
    "    gemini_alex = call_gemini(conversation, gemini_model=\"gemini-2.5-flash-lite\")\n",
    "    display(Markdown(f\"### Gemini:(alex) \\n{gemini_alex}\\n\"))\n",
    "    conversation += f\"\\nAlex: {gemini_alex}\\n\"\n",
    "\n",
    "    anthropic_charlie = call_anthropic(conversation, anthropic_model=\"claude-3-5-haiku-latest\")\n",
    "    display(Markdown(f\"### Claude:(charlie) \\n{anthropic_charlie}\\n\"))\n",
    "    conversation += f\"\\nCharlie: {anthropic_charlie}\\n\"\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
